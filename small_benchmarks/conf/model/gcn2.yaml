# @package _group_
name: GCN2
norm: true
loop: false
params:

  Cora:
    architecture:
      num_layers: 64
      hidden_channels: 64
      dropout: 0.6
      alpha: 0.1
      theta: 0.5
    num_parts: 2
    batch_size: 1
    num_workers: 0
    lr: 0.01
    reg_weight_decay: 0.01
    nonreg_weight_decay: 5e-4
    grad_norm: null
    epochs: 1000
    runs: 10

  CiteSeer:
    architecture:
      num_layers: 32
      hidden_channels: 256
      dropout: 0.7
      alpha: 0.1
      theta: 0.6
    num_parts: 40
    batch_size: 20
    num_workers: 0
    lr: 0.01
    reg_weight_decay: 0.01
    nonreg_weight_decay: 5e-4
    grad_norm: 1.0
    epochs: 1000
    runs: 10

  PubMed:
    architecture:
      num_layers: 16
      hidden_channels: 256
      dropout: 0.5
      alpha: 0.1
      theta: 0.4
    num_parts: 4
    batch_size: 2
    num_workers: 0
    lr: 0.01
    reg_weight_decay: 5e-4
    nonreg_weight_decay: 5e-4
    grad_norm: null
    epochs: 1000
    runs: 10

  CoauthorCS:
    architecture:
      num_layers: 16
      hidden_channels: 64
      dropout: 0.5
      alpha: 0.1
      theta: 0.5
    num_parts: 16
    batch_size: 8
    num_workers: 0
    lr: 0.01
    reg_weight_decay: 0.01
    nonreg_weight_decay: 5e-4
    grad_norm: null
    epochs: 1000
    runs: 10

  CoauthorPhysics:
    architecture:
      num_layers: 16
      hidden_channels: 64
      dropout: 0.5
      alpha: 0.1
      theta: 0.5
    num_parts: 2
    batch_size: 1
    num_workers: 0
    lr: 0.01
    reg_weight_decay: 0.01
    nonreg_weight_decay: 5e-4
    grad_norm: 1.0
    epochs: 1000
    runs: 10

  AmazonComputers:
    architecture:
      num_layers: 16
      hidden_channels: 64
      dropout: 0.2
      alpha: 0.1
      theta: 0.5
    num_parts: 32
    batch_size: 16
    num_workers: 0
    lr: 0.01
    reg_weight_decay: 0.01
    nonreg_weight_decay: 5e-4
    grad_norm: 1.0
    epochs: 300
    runs: 10

  AmazonPhoto:
    architecture:
      num_layers: 16
      hidden_channels: 64
      dropout: 0.5
      alpha: 0.1
      theta: 0.5
    num_parts: 4
    batch_size: 2
    num_workers: 0
    lr: 0.01
    reg_weight_decay: 0.01
    nonreg_weight_decay: 5e-4
    grad_norm: 1.0
    epochs: 1000
    runs: 10

  WikiCS:
    architecture:
      num_layers: 4
      hidden_channels: 128
      dropout: 0.5
      alpha: 0.1
      theta: 0.5
    num_parts: 4
    batch_size: 2
    num_workers: 0
    lr: 0.01
    reg_weight_decay: 5e-4
    nonreg_weight_decay: 5e-4
    grad_norm: null
    epochs: 1000
    runs: 10
